# train: false

model:
    name: cnn
    embedding_dim: 300
    filter_sizes: [1,2,3]
    num_filters: 10
    dropout_keep_prob: 0.7
    l2_reg_lambda: 3
    batch_size: 64
    num_epochs: 10
    evaluate_every: 100
    checkpoint_every: 100
    allow_soft_placement: true
    log_device_placement: false
    max_words_in_sentence: 3
    vocab_size: 3000000
    store_path: models/cnn2.ckpt
    word2vec_path: resources/GoogleNews-vectors-negative300.bin

test_output_path: results/cnn2.json
experiment_name: "CNN model"
description: "A CNN model with static word2vec only on connective_token."
tags: ['cnn', 'static', 'word2vec', 'connective_token', 'explicit_only']

# Each extractor has a name from main.extractor_handlers, which points to a class
# where any additional params are used to initiate the extractor class.

extractors:
    # -
    #     name: bag_of_words
    #     max_vocab_size: 5000
    #     vocab_indices_path: resources/conll16st-en-zh-dev-train_LDC2016E50/vocab.txt
    #     argument: connective_token
    # -
    #     name: word2vec
    #     path: resources/GoogleNews-vectors-negative300.bin
    #     argument: connective_token
    # -
    #     name: onehot
    #     vocab_indices_path: resources/conll16st-en-zh-dev-train_LDC2016E50/vocab.txt
     -
         name: vocab_indices
         vocab_indices_path: resources/word2vec_indices.txt
         sentence_max_length: 5
         argument: connective_token
    # -
    #     name: cbow
    #     path: resources/GoogleNews-vectors-negative300.bin
    #     argument: connective_token
    # -
    #     name: cbow
    #     path: resources/GoogleNews-vectors-negative300.bin
    #     argument: arg2_text
    # -
    #     name: cbow
    #     path: resources/GoogleNews-vectors-negative300.bin
    #     argument: connective_token
