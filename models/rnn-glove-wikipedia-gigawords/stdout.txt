Starting job 16079467 ("rnn-glove-wikipedia-gigawords") on c13-29 at mån dec 5 22:25:24 CET 2016
Python environment is set up
Copying files to /work/jobs/16079467.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16079467.d/resources/
DATA_BASE_PATH: /work/jobs/16079467.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Using Theano backend.
[2016-12-05 22:28] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-05 22:28]     config 'epochs':  (1000)
[2016-12-05 22:28]     config 'epochs_len':  (-1)
[2016-12-05 22:28]     config 'epochs_patience':  (20)
[2016-12-05 22:28]     config 'batch_size':  (64)
[2016-12-05 22:28]     config 'snapshot_size':  (2048)
[2016-12-05 22:28]     config 'random_per_sample':  (32)
[2016-12-05 22:28]     config 'words_dim': 20 (20)
[2016-12-05 22:28]     config 'focus_dim':  (4)
[2016-12-05 22:28]     config 'rnn_dim':  (20)
[2016-12-05 22:28]     config 'final_dim':  (100)
[2016-12-05 22:28]     config 'arg1_len':  (100)
[2016-12-05 22:28]     config 'arg2_len':  (100)
[2016-12-05 22:28]     config 'conn_len':  (10)
[2016-12-05 22:28]     config 'punc_len':  (2)
[2016-12-05 22:28]     config 'words_dropout':  (0.1)
[2016-12-05 22:28]     config 'focus_dropout_W':  (0.33)
[2016-12-05 22:28]     config 'focus_dropout_U':  (0.66)
[2016-12-05 22:28]     config 'rnn_dropout_W':  (0.33)
[2016-12-05 22:28]     config 'rnn_dropout_U':  (0.33)
[2016-12-05 22:28]     config 'final_dropout':  (0.5)
[2016-12-05 22:28]     config 'filter_fn_name':  (conn_eq_0)
[2016-12-05 22:28]     config 'words2vec_bin':  (None)
[2016-12-05 22:28]     config 'words2vec_txt': /work/jobs/16079467.d/resources/ (None)
[2016-12-05 22:28]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-05 22:28]   args.train_dir: /work/jobs/16079467.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-05 22:28]   args.valid_dir: /work/jobs/16079467.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-05 22:28]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-05 22:28]   os.getenv("THEANO_FLAGS"): None
[2016-12-05 22:28]   filter_types: None
[2016-12-05 22:28]   filter_senses: None
[2016-12-05 22:28]   filter_fn_name: conn_eq_0
[2016-12-05 22:28]   config: {u'words_dim': 20, u'words2vec_txt': u'/work/jobs/16079467.d/resources/'}
[2016-12-05 22:28] load dataset for training (/work/jobs/16079467.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-05 22:34] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 15246, relation tokens: 482545
[2016-12-05 22:34] load dataset for validation (/work/jobs/16079467.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-05 22:35] lang: ?, doc_ids: 79, words: 39712, rel_ids: 699, relation tokens: 20137
[2016-12-05 22:35] build indexes
[2016-12-05 22:35]   rel_senses2id: 21, words2id: 43918
[2016-12-05 22:35] Fast version of gensim.models.doc2vec is being used
[2016-12-05 22:35] 'pattern' package found; tag filters are available for English
[2016-12-05 22:35] loading projection weights from /work/jobs/16079467.d/resources/
Traceback (most recent call last):
  File "./v34/train.py", line 154, in <module>
    init_weights = load_word2vec(indexes['words2id'], indexes_size['words2id'], words_dim, words2vec_bin, words2vec_txt)
  File "/work/jobs/16079467.d/conll16st-v34-focused-rnns/v34/data_utils.py", line 229, in load_word2vec
    model = word2vec.Word2Vec.load_word2vec_format(words2vec_txt)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/gensim/models/word2vec.py", line 1171, in load_word2vec_format
    with utils.smart_open(fname) as fin:
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 127, in smart_open
    return file_smart_open(parsed_uri.uri_path, mode)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 558, in file_smart_open
    return open(fname, mode)
IOError: [Errno 21] Is a directory: u'/work/jobs/16079467.d/resources/'
> /usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py(558)file_smart_open()
-> return open(fname, mode)
(Pdb) 

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16079467.ba+   5299160K   4804611K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16079467     rnn-glove+          4                         00:09:45      0:0 

Job 16079467 ("rnn-glove-wikipedia-gigawords") completed on c13-29 at mån dec 5 22:35:07 CET 2016
Starting job 16079551 ("rnn-glove-wikipedia-gigawords") on c15-36 at mån dec 5 22:44:38 CET 2016
An unexpected error has occurred.
Please consider posting the following information to the
conda GitHub issue tracker at:

    https://github.com/conda/conda/issues



Current conda install:

               platform : linux-64
          conda version : 4.2.13
       conda is private : False
      conda-env version : 4.2.13
    conda-build version : not installed
         python version : 2.7.12.final.0
       requests version : 2.11.1
       root environment : /usit/abel/u1/jimmycallin/miniconda2  (writable)
    default environment : /usit/abel/u1/jimmycallin/miniconda2
       envs directories : /usit/abel/u1/jimmycallin/miniconda2/envs
          package cache : /usit/abel/u1/jimmycallin/miniconda2/pkgs
           channel URLs : https://repo.continuum.io/pkgs/free/linux-64
                          https://repo.continuum.io/pkgs/free/noarch
                          https://repo.continuum.io/pkgs/pro/linux-64
                          https://repo.continuum.io/pkgs/pro/noarch
            config file : None
           offline mode : False



`$ /usit/abel/u1/jimmycallin/miniconda2/bin/conda ..checkenv bash rnn`




    Traceback (most recent call last):
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/exceptions.py", line 479, in conda_exception_handler
        return_value = func(*args, **kwargs)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/cli/main.py", line 94, in _main
        activate.main()
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/cli/activate.py", line 148, in main
        conda.install.symlink_conda(prefix, context.root_dir, shell)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/install.py", line 541, in symlink_conda
        symlink_conda_hlp(prefix, root_dir, where, symlink_fn)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/install.py", line 558, in symlink_conda_hlp
        symlink_fn(root_file, prefix_file)
    OSError: [Errno 2] No such file or directory

Python environment is set up
Copying files to /work/jobs/16079551.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16079551.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16079551.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Traceback (most recent call last):
  File "./v34/train.py", line 16, in <module>
    from keras.models import Model
ImportError: No module named keras.models

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16079551.ba+    220920K      2107K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16079551     rnn-glove+          4                         00:01:59      0:0 

Job 16079551 ("rnn-glove-wikipedia-gigawords") completed on c15-36 at mån dec 5 22:46:35 CET 2016
Starting job 16079799 ("rnn-glove-wikipedia-gigawords") on c13-1 at mån dec 5 23:02:16 CET 2016
An unexpected error has occurred.
Please consider posting the following information to the
conda GitHub issue tracker at:

    https://github.com/conda/conda/issues



Current conda install:

               platform : linux-64
          conda version : 4.2.13
       conda is private : False
      conda-env version : 4.2.13
    conda-build version : not installed
         python version : 2.7.12.final.0
       requests version : 2.11.1
       root environment : /usit/abel/u1/jimmycallin/miniconda2  (writable)
    default environment : /usit/abel/u1/jimmycallin/miniconda2
       envs directories : /usit/abel/u1/jimmycallin/miniconda2/envs
          package cache : /usit/abel/u1/jimmycallin/miniconda2/pkgs
           channel URLs : https://repo.continuum.io/pkgs/free/linux-64
                          https://repo.continuum.io/pkgs/free/noarch
                          https://repo.continuum.io/pkgs/pro/linux-64
                          https://repo.continuum.io/pkgs/pro/noarch
            config file : None
           offline mode : False



`$ /usit/abel/u1/jimmycallin/miniconda2/bin/conda ..checkenv bash rnn`




    Traceback (most recent call last):
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/exceptions.py", line 479, in conda_exception_handler
        return_value = func(*args, **kwargs)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/cli/main.py", line 94, in _main
        activate.main()
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/cli/activate.py", line 148, in main
        conda.install.symlink_conda(prefix, context.root_dir, shell)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/install.py", line 541, in symlink_conda
        symlink_conda_hlp(prefix, root_dir, where, symlink_fn)
      File "/usit/abel/u1/jimmycallin/miniconda2/lib/python2.7/site-packages/conda/install.py", line 558, in symlink_conda_hlp
        symlink_fn(root_file, prefix_file)
    OSError: [Errno 2] No such file or directory

Python environment is set up
Copying files to /work/jobs/16079799.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16079799.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16079799.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Traceback (most recent call last):
  File "./v34/train.py", line 16, in <module>
    from keras.models import Model
ImportError: No module named keras.models

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16079799.ba+    220920K      2308K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16079799     rnn-glove+          4                         00:02:37      0:0 

Job 16079799 ("rnn-glove-wikipedia-gigawords") completed on c13-1 at mån dec 5 23:04:49 CET 2016
Starting job 16080087 ("rnn-glove-wikipedia-gigawords") on c15-30 at tis dec 6 00:05:51 CET 2016
Python environment is set up
Copying files to /work/jobs/16080087.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16080087.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16080087.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Using Theano backend.
[2016-12-06 00:11] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 00:11]     config 'epochs':  (1000)
[2016-12-06 00:11]     config 'epochs_len':  (-1)
[2016-12-06 00:11]     config 'epochs_patience':  (20)
[2016-12-06 00:11]     config 'batch_size':  (64)
[2016-12-06 00:11]     config 'snapshot_size':  (2048)
[2016-12-06 00:11]     config 'random_per_sample':  (32)
[2016-12-06 00:11]     config 'words_dim': 20 (20)
[2016-12-06 00:11]     config 'focus_dim':  (4)
[2016-12-06 00:11]     config 'rnn_dim':  (20)
[2016-12-06 00:11]     config 'final_dim':  (100)
[2016-12-06 00:11]     config 'arg1_len':  (100)
[2016-12-06 00:11]     config 'arg2_len':  (100)
[2016-12-06 00:11]     config 'conn_len':  (10)
[2016-12-06 00:11]     config 'punc_len':  (2)
[2016-12-06 00:11]     config 'words_dropout':  (0.1)
[2016-12-06 00:11]     config 'focus_dropout_W':  (0.33)
[2016-12-06 00:11]     config 'focus_dropout_U':  (0.66)
[2016-12-06 00:11]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 00:11]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 00:11]     config 'final_dropout':  (0.5)
[2016-12-06 00:11]     config 'filter_fn_name':  (conn_eq_0)
[2016-12-06 00:11]     config 'words2vec_bin':  (None)
[2016-12-06 00:11]     config 'words2vec_txt': /work/jobs/16080087.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-06 00:11]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 00:11]   args.train_dir: /work/jobs/16080087.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 00:11]   args.valid_dir: /work/jobs/16080087.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 00:11]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 00:11]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 00:11]   filter_types: None
[2016-12-06 00:11]   filter_senses: None
[2016-12-06 00:11]   filter_fn_name: conn_eq_0
[2016-12-06 00:11]   config: {u'words_dim': 20, u'words2vec_txt': u'/work/jobs/16080087.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt'}
[2016-12-06 00:11] load dataset for training (/work/jobs/16080087.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 00:18] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 15246, relation tokens: 482545
[2016-12-06 00:18] load dataset for validation (/work/jobs/16080087.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 00:18] lang: ?, doc_ids: 79, words: 39712, rel_ids: 699, relation tokens: 20137
[2016-12-06 00:18] build indexes
[2016-12-06 00:18]   rel_senses2id: 21, words2id: 43918
[2016-12-06 00:18] Fast version of gensim.models.doc2vec is being used
[2016-12-06 00:18] 'pattern' package found; tag filters are available for English
[2016-12-06 00:18] loading projection weights from /work/jobs/16080087.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 00:18] Fast version of gensim.models.word2vec is being used
[2016-12-06 00:18] consider setting layer size to a multiple of 4 for greater performance
[2016-12-06 00:18] loaded (400000, 50) matrix from /work/jobs/16080087.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 00:18] build model
Traceback (most recent call last):
  File "./v34/train.py", line 208, in <module>
    arg1_rnns = focused_rnns(arg1_ids)
  File "./v34/train.py", line 197, in focused_rnns
    rnn_in = merge([arg1_emb, rnn_focus], mode='mul')
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 1420, in merge
    name=name)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 1118, in __init__
    self.add_inbound_node(layers, node_indices, tensor_indices)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 543, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 154, in create_node
    output_masks = to_list(outbound_layer.compute_mask(input_tensors, input_masks))
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 1311, in compute_mask
    'but was passed an input mask: ' + str(mask))
Exception: Merge does not support masking, but was passed an input mask: [Elemwise{neq,no_inplace}.0, Elemwise{neq,no_inplace}.0]
> /usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py(1311)compute_mask()
-> 'but was passed an input mask: ' + str(mask))
(Pdb) 

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16080087.ba+   5542916K   4904920K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16080087     rnn-glove+          4                         00:13:21      0:0 

Job 16080087 ("rnn-glove-wikipedia-gigawords") completed on c15-30 at tis dec 6 00:19:08 CET 2016
Starting job 16080211 ("rnn-glove-wikipedia-gigawords") on c15-31 at tis dec 6 00:24:43 CET 2016
Python environment is set up
Copying files to /work/jobs/16080211.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16080211.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16080211.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Using Theano backend.
[2016-12-06 00:27] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 00:27]     config 'epochs':  (1000)
[2016-12-06 00:27]     config 'epochs_len':  (-1)
[2016-12-06 00:27]     config 'epochs_patience':  (20)
[2016-12-06 00:27]     config 'batch_size':  (64)
[2016-12-06 00:27]     config 'snapshot_size':  (2048)
[2016-12-06 00:27]     config 'random_per_sample':  (32)
[2016-12-06 00:27]     config 'words_dim': 20 (20)
[2016-12-06 00:27]     config 'focus_dim':  (4)
[2016-12-06 00:27]     config 'rnn_dim':  (20)
[2016-12-06 00:27]     config 'final_dim':  (100)
[2016-12-06 00:27]     config 'arg1_len':  (100)
[2016-12-06 00:27]     config 'arg2_len':  (100)
[2016-12-06 00:27]     config 'conn_len':  (10)
[2016-12-06 00:27]     config 'punc_len':  (2)
[2016-12-06 00:27]     config 'words_dropout':  (0.1)
[2016-12-06 00:27]     config 'focus_dropout_W':  (0.33)
[2016-12-06 00:27]     config 'focus_dropout_U':  (0.66)
[2016-12-06 00:27]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 00:27]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 00:27]     config 'final_dropout':  (0.5)
[2016-12-06 00:27]     config 'filter_fn_name':  (conn_eq_0)
[2016-12-06 00:27]     config 'words2vec_bin':  (None)
[2016-12-06 00:27]     config 'words2vec_txt': /work/jobs/16080211.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-06 00:27]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 00:27]   args.train_dir: /work/jobs/16080211.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 00:27]   args.valid_dir: /work/jobs/16080211.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 00:27]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 00:27]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 00:27]   filter_types: None
[2016-12-06 00:27]   filter_senses: None
[2016-12-06 00:27]   filter_fn_name: conn_eq_0
[2016-12-06 00:27]   config: {u'words_dim': 20, u'words2vec_txt': u'/work/jobs/16080211.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt'}
[2016-12-06 00:27] load dataset for training (/work/jobs/16080211.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 00:33] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 15246, relation tokens: 482545
[2016-12-06 00:33] load dataset for validation (/work/jobs/16080211.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 00:33] lang: ?, doc_ids: 79, words: 39712, rel_ids: 699, relation tokens: 20137
[2016-12-06 00:33] build indexes
[2016-12-06 00:33]   rel_senses2id: 21, words2id: 43918
[2016-12-06 00:33] Fast version of gensim.models.doc2vec is being used
[2016-12-06 00:33] 'pattern' package found; tag filters are available for English
[2016-12-06 00:33] loading projection weights from /work/jobs/16080211.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 00:33] Fast version of gensim.models.word2vec is being used
[2016-12-06 00:33] consider setting layer size to a multiple of 4 for greater performance
[2016-12-06 00:34] loaded (400000, 50) matrix from /work/jobs/16080211.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 00:34] build model
[2016-12-06 00:34]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-06 00:34]     config 'optimizer':  (adam)
[2016-12-06 00:34] initialize weights
[2016-12-06 00:34] prepare snapshots
[2016-12-06 00:34] train model
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:43] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:43] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:43] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:43] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:43] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:43] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:43] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:43] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:43] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:43] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:44] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:44] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:45] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:45] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:45] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:45] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:45] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:45] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:45] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:45] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:46] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:46] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '11288' (I am process '16046')
[2016-12-06 00:47] Waiting for existing lock by process '11288' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:47] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:48] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:48] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:48] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:48] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:48] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:48] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:48] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:48] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:49] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:49] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:50] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:50] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
INFO (theano.gof.compilelock): Waiting for existing lock by process '24727' (I am process '16046')
[2016-12-06 00:50] Waiting for existing lock by process '24727' (I am process '16046')
INFO (theano.gof.compilelock): To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
[2016-12-06 00:50] To manually release the lock, delete /cluster/home/jimmycallin/.theano/compiledir_Linux-2.6-el6.x86_64-x86_64-with-centos-6.8-Final-x86_64-2.7.12-64/lock_dir
Traceback (most recent call last):
  File "./v34/train.py", line 264, in <module>
    history = model.fit_generator(train_iter, nb_epoch=epochs, samples_per_epoch=epochs_len, validation_data=valid_snapshot, callbacks=callbacks, verbose=2)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/training.py", line 1419, in fit_generator
    callbacks.on_epoch_end(epoch, epoch_logs)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/callbacks.py", line 39, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/callbacks.py", line 290, in on_epoch_end
    self.model.save_weights(filepath, overwrite=True)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py", line 2251, in save_weights
    import h5py
ImportError: No module named h5py
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
arg1_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
arg2_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
conn_ids (InputLayer)              (None, 10)          0                                            
____________________________________________________________________________________________________
punc_ids (InputLayer)              (None, 2)           0                                            
____________________________________________________________________________________________________
shared_emb (Embedding)             multiple            878360      arg1_ids[0][0]                   
                                                                   arg2_ids[0][0]                   
                                                                   conn_ids[0][0]                   
                                                                   punc_ids[0][0]                   
____________________________________________________________________________________________________
gru_1 (GRU)                        (None, 100, 4)      300         shared_emb[0][0]                 
____________________________________________________________________________________________________
gru_11 (GRU)                       (None, 10, 4)       300         shared_emb[2][0]                 
____________________________________________________________________________________________________
gru_16 (GRU)                       (None, 2, 4)        300         shared_emb[3][0]                 
____________________________________________________________________________________________________
gru_6 (GRU)                        (None, 100, 4)      300         shared_emb[1][0]                 
____________________________________________________________________________________________________
timedistributed_1 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_10 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_11 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_12 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_13 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_14 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_15 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_16 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_2 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_3 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_4 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_5 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_6 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_7 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_8 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_9 (TimeDistributed)(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
merge_1 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_1[0][0]          
____________________________________________________________________________________________________
merge_10 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_10[0][0]         
____________________________________________________________________________________________________
merge_11 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_11[0][0]         
____________________________________________________________________________________________________
merge_12 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_12[0][0]         
____________________________________________________________________________________________________
merge_13 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_13[0][0]         
____________________________________________________________________________________________________
merge_14 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_14[0][0]         
____________________________________________________________________________________________________
merge_15 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_15[0][0]         
____________________________________________________________________________________________________
merge_16 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_16[0][0]         
____________________________________________________________________________________________________
merge_2 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_2[0][0]          
____________________________________________________________________________________________________
merge_3 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_3[0][0]          
____________________________________________________________________________________________________
merge_4 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_4[0][0]          
____________________________________________________________________________________________________
merge_5 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_5[0][0]          
____________________________________________________________________________________________________
merge_6 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_6[0][0]          
____________________________________________________________________________________________________
merge_7 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_7[0][0]          
____________________________________________________________________________________________________
merge_8 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_8[0][0]          
____________________________________________________________________________________________________
merge_9 (Merge)                    (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_9[0][0]          
____________________________________________________________________________________________________
gru_10 (GRU)                       (None, 20)          2460        merge_8[0][0]                    
____________________________________________________________________________________________________
gru_12 (GRU)                       (None, 20)          2460        merge_9[0][0]                    
____________________________________________________________________________________________________
gru_13 (GRU)                       (None, 20)          2460        merge_10[0][0]                   
____________________________________________________________________________________________________
gru_14 (GRU)                       (None, 20)          2460        merge_11[0][0]                   
____________________________________________________________________________________________________
gru_15 (GRU)                       (None, 20)          2460        merge_12[0][0]                   
____________________________________________________________________________________________________
gru_17 (GRU)                       (None, 20)          2460        merge_13[0][0]                   
____________________________________________________________________________________________________
gru_18 (GRU)                       (None, 20)          2460        merge_14[0][0]                   
____________________________________________________________________________________________________
gru_19 (GRU)                       (None, 20)          2460        merge_15[0][0]                   
____________________________________________________________________________________________________
gru_2 (GRU)                        (None, 20)          2460        merge_1[0][0]                    
____________________________________________________________________________________________________
gru_20 (GRU)                       (None, 20)          2460        merge_16[0][0]                   
____________________________________________________________________________________________________
gru_3 (GRU)                        (None, 20)          2460        merge_2[0][0]                    
____________________________________________________________________________________________________
gru_4 (GRU)                        (None, 20)          2460        merge_3[0][0]                    
____________________________________________________________________________________________________
gru_5 (GRU)                        (None, 20)          2460        merge_4[0][0]                    
____________________________________________________________________________________________________
gru_7 (GRU)                        (None, 20)          2460        merge_5[0][0]                    
____________________________________________________________________________________________________
gru_8 (GRU)                        (None, 20)          2460        merge_6[0][0]                    
____________________________________________________________________________________________________
gru_9 (GRU)                        (None, 20)          2460        merge_7[0][0]                    
____________________________________________________________________________________________________
merge_17 (Merge)                   (None, 320)         0           gru_2[0][0]                      
                                                                   gru_3[0][0]                      
                                                                   gru_4[0][0]                      
                                                                   gru_5[0][0]                      
                                                                   gru_7[0][0]                      
                                                                   gru_8[0][0]                      
                                                                   gru_9[0][0]                      
                                                                   gru_10[0][0]                     
                                                                   gru_12[0][0]                     
                                                                   gru_13[0][0]                     
                                                                   gru_14[0][0]                     
                                                                   gru_15[0][0]                     
                                                                   gru_17[0][0]                     
                                                                   gru_18[0][0]                     
                                                                   gru_19[0][0]                     
                                                                   gru_20[0][0]                     
____________________________________________________________________________________________________
dense_1 (Dense)                    (None, 100)         32100       merge_17[0][0]                   
____________________________________________________________________________________________________
srelu_1 (SReLU)                    (None, 100)         400         dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 100)         0           srelu_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 21)          2121        dropout_1[0][0]                  
____________________________________________________________________________________________________
rsenses (Activation)               (None, 21)          0           dense_2[0][0]                    
====================================================================================================
Total params: 953541
____________________________________________________________________________________________________
Epoch 1/1000
> /usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/topology.py(2251)save_weights()
-> import h5py
(Pdb) 

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16080211.ba+   7424452K   5906662K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16080211     rnn-glove+          4                         00:27:43      0:0 

Job 16080211 ("rnn-glove-wikipedia-gigawords") completed on c15-31 at tis dec 6 00:52:23 CET 2016
Starting job 16080345 ("rnn-glove-wikipedia-gigawords") on c15-29 at tis dec 6 01:10:45 CET 2016
Python environment is set up
Copying files to /work/jobs/16080345.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16080345.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16080345.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
Using Theano backend.
[2016-12-06 01:13] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 01:13]     config 'epochs':  (1000)
[2016-12-06 01:13]     config 'epochs_len':  (-1)
[2016-12-06 01:13]     config 'epochs_patience':  (20)
[2016-12-06 01:13]     config 'batch_size':  (64)
[2016-12-06 01:13]     config 'snapshot_size':  (2048)
[2016-12-06 01:13]     config 'random_per_sample':  (32)
[2016-12-06 01:13]     config 'words_dim': 20 (20)
[2016-12-06 01:13]     config 'focus_dim':  (4)
[2016-12-06 01:13]     config 'rnn_dim':  (20)
[2016-12-06 01:13]     config 'final_dim':  (100)
[2016-12-06 01:13]     config 'arg1_len':  (100)
[2016-12-06 01:13]     config 'arg2_len':  (100)
[2016-12-06 01:13]     config 'conn_len':  (10)
[2016-12-06 01:13]     config 'punc_len':  (2)
[2016-12-06 01:13]     config 'words_dropout':  (0.1)
[2016-12-06 01:13]     config 'focus_dropout_W':  (0.33)
[2016-12-06 01:13]     config 'focus_dropout_U':  (0.66)
[2016-12-06 01:13]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 01:13]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 01:13]     config 'final_dropout':  (0.5)
[2016-12-06 01:13]     config 'filter_fn_name':  (conn_eq_0)
[2016-12-06 01:13]     config 'words2vec_bin':  (None)
[2016-12-06 01:13]     config 'words2vec_txt': /work/jobs/16080345.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-06 01:13]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 01:13]   args.train_dir: /work/jobs/16080345.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 01:13]   args.valid_dir: /work/jobs/16080345.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 01:13]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 01:13]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 01:13]   filter_types: None
[2016-12-06 01:13]   filter_senses: None
[2016-12-06 01:13]   filter_fn_name: conn_eq_0
[2016-12-06 01:13]   config: {u'words_dim': 20, u'words2vec_txt': u'/work/jobs/16080345.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt'}
[2016-12-06 01:13] load dataset for training (/work/jobs/16080345.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 01:19] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 15246, relation tokens: 482545
[2016-12-06 01:19] load dataset for validation (/work/jobs/16080345.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 01:19] lang: ?, doc_ids: 79, words: 39712, rel_ids: 699, relation tokens: 20137
[2016-12-06 01:19] build indexes
[2016-12-06 01:19]   rel_senses2id: 21, words2id: 43918
[2016-12-06 01:19] Fast version of gensim.models.doc2vec is being used
[2016-12-06 01:19] 'pattern' package found; tag filters are available for English
[2016-12-06 01:19] loading projection weights from /work/jobs/16080345.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 01:19] Fast version of gensim.models.word2vec is being used
[2016-12-06 01:19] consider setting layer size to a multiple of 4 for greater performance
[2016-12-06 01:20] loaded (400000, 50) matrix from /work/jobs/16080345.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 01:20] build model
[2016-12-06 01:20]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-06 01:20]     config 'optimizer':  (adam)
[2016-12-06 01:20] initialize weights
[2016-12-06 01:20] prepare snapshots
[2016-12-06 01:20] train model
[2016-12-06 03:53] training finished
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
arg1_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
arg2_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
conn_ids (InputLayer)              (None, 10)          0                                            
____________________________________________________________________________________________________
punc_ids (InputLayer)              (None, 2)           0                                            
____________________________________________________________________________________________________
shared_emb (Embedding)             multiple            878360      arg1_ids[0][0]                   
                                                                   arg2_ids[0][0]                   
                                                                   conn_ids[0][0]                   
                                                                   punc_ids[0][0]                   
____________________________________________________________________________________________________
gru_1 (GRU)                        (None, 100, 4)      300         shared_emb[0][0]                 
____________________________________________________________________________________________________
gru_11 (GRU)                       (None, 10, 4)       300         shared_emb[2][0]                 
____________________________________________________________________________________________________
gru_16 (GRU)                       (None, 2, 4)        300         shared_emb[3][0]                 
____________________________________________________________________________________________________
gru_6 (GRU)                        (None, 100, 4)      300         shared_emb[1][0]                 
____________________________________________________________________________________________________
timedistributed_1 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_10 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_11 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_12 (TimeDistributed(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
timedistributed_13 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_14 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_15 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_16 (TimeDistributed(None, 2, 20)       0           gru_16[0][0]                     
____________________________________________________________________________________________________
timedistributed_2 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_3 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_4 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_5 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_6 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_7 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_8 (TimeDistributed)(None, 100, 20)     0           gru_6[0][0]                      
____________________________________________________________________________________________________
timedistributed_9 (TimeDistributed)(None, 10, 20)      0           gru_11[0][0]                     
____________________________________________________________________________________________________
merge_1 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_1[0][0]          
____________________________________________________________________________________________________
merge_10 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_10[0][0]         
____________________________________________________________________________________________________
merge_11 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_11[0][0]         
____________________________________________________________________________________________________
merge_12 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_12[0][0]         
____________________________________________________________________________________________________
merge_13 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_13[0][0]         
____________________________________________________________________________________________________
merge_14 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_14[0][0]         
____________________________________________________________________________________________________
merge_15 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_15[0][0]         
____________________________________________________________________________________________________
merge_16 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_16[0][0]         
____________________________________________________________________________________________________
merge_2 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_2[0][0]          
____________________________________________________________________________________________________
merge_3 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_3[0][0]          
____________________________________________________________________________________________________
merge_4 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_4[0][0]          
____________________________________________________________________________________________________
merge_5 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_5[0][0]          
____________________________________________________________________________________________________
merge_6 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_6[0][0]          
____________________________________________________________________________________________________
merge_7 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_7[0][0]          
____________________________________________________________________________________________________
merge_8 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_8[0][0]          
____________________________________________________________________________________________________
merge_9 (Merge)                    (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_9[0][0]          
____________________________________________________________________________________________________
gru_10 (GRU)                       (None, 20)          2460        merge_8[0][0]                    
____________________________________________________________________________________________________
gru_12 (GRU)                       (None, 20)          2460        merge_9[0][0]                    
____________________________________________________________________________________________________
gru_13 (GRU)                       (None, 20)          2460        merge_10[0][0]                   
____________________________________________________________________________________________________
gru_14 (GRU)                       (None, 20)          2460        merge_11[0][0]                   
____________________________________________________________________________________________________
gru_15 (GRU)                       (None, 20)          2460        merge_12[0][0]                   
____________________________________________________________________________________________________
gru_17 (GRU)                       (None, 20)          2460        merge_13[0][0]                   
____________________________________________________________________________________________________
gru_18 (GRU)                       (None, 20)          2460        merge_14[0][0]                   
____________________________________________________________________________________________________
gru_19 (GRU)                       (None, 20)          2460        merge_15[0][0]                   
____________________________________________________________________________________________________
gru_2 (GRU)                        (None, 20)          2460        merge_1[0][0]                    
____________________________________________________________________________________________________
gru_20 (GRU)                       (None, 20)          2460        merge_16[0][0]                   
____________________________________________________________________________________________________
gru_3 (GRU)                        (None, 20)          2460        merge_2[0][0]                    
____________________________________________________________________________________________________
gru_4 (GRU)                        (None, 20)          2460        merge_3[0][0]                    
____________________________________________________________________________________________________
gru_5 (GRU)                        (None, 20)          2460        merge_4[0][0]                    
____________________________________________________________________________________________________
gru_7 (GRU)                        (None, 20)          2460        merge_5[0][0]                    
____________________________________________________________________________________________________
gru_8 (GRU)                        (None, 20)          2460        merge_6[0][0]                    
____________________________________________________________________________________________________
gru_9 (GRU)                        (None, 20)          2460        merge_7[0][0]                    
____________________________________________________________________________________________________
merge_17 (Merge)                   (None, 320)         0           gru_2[0][0]                      
                                                                   gru_3[0][0]                      
                                                                   gru_4[0][0]                      
                                                                   gru_5[0][0]                      
                                                                   gru_7[0][0]                      
                                                                   gru_8[0][0]                      
                                                                   gru_9[0][0]                      
                                                                   gru_10[0][0]                     
                                                                   gru_12[0][0]                     
                                                                   gru_13[0][0]                     
                                                                   gru_14[0][0]                     
                                                                   gru_15[0][0]                     
                                                                   gru_17[0][0]                     
                                                                   gru_18[0][0]                     
                                                                   gru_19[0][0]                     
                                                                   gru_20[0][0]                     
____________________________________________________________________________________________________
dense_1 (Dense)                    (None, 100)         32100       merge_17[0][0]                   
____________________________________________________________________________________________________
srelu_1 (SReLU)                    (None, 100)         400         dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 100)         0           srelu_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 21)          2121        dropout_1[0][0]                  
____________________________________________________________________________________________________
rsenses (Activation)               (None, 21)          0           dense_2[0][0]                    
====================================================================================================
Total params: 953541
____________________________________________________________________________________________________
Epoch 1/1000
121s - loss: 0.2060 - acc: 0.9726 - val_loss: 2.2724 - val_acc: 0.2675
Epoch 2/1000
118s - loss: 0.0697 - acc: 0.9774 - val_loss: 2.1968 - val_acc: 0.2690
Epoch 3/1000
118s - loss: 0.0723 - acc: 0.9757 - val_loss: 2.2432 - val_acc: 0.2675
Epoch 4/1000
117s - loss: 0.0716 - acc: 0.9775 - val_loss: 2.1779 - val_acc: 0.2690
Epoch 5/1000
117s - loss: 0.0686 - acc: 0.9792 - val_loss: 2.2212 - val_acc: 0.2675
Epoch 6/1000
117s - loss: 0.0681 - acc: 0.9776 - val_loss: 2.1839 - val_acc: 0.2690
Epoch 7/1000
117s - loss: 0.0697 - acc: 0.9775 - val_loss: 2.1793 - val_acc: 0.2675
Epoch 8/1000
117s - loss: 0.0653 - acc: 0.9791 - val_loss: 2.1796 - val_acc: 0.2690
Epoch 9/1000
117s - loss: 0.0683 - acc: 0.9781 - val_loss: 2.1896 - val_acc: 0.2675
Epoch 10/1000
117s - loss: 0.0687 - acc: 0.9780 - val_loss: 2.1551 - val_acc: 0.2675
Epoch 11/1000
117s - loss: 0.0672 - acc: 0.9790 - val_loss: 2.1490 - val_acc: 0.2675
Epoch 12/1000
117s - loss: 0.0697 - acc: 0.9772 - val_loss: 2.1563 - val_acc: 0.2690
Epoch 13/1000
117s - loss: 0.0686 - acc: 0.9778 - val_loss: 2.1724 - val_acc: 0.2675
Epoch 14/1000
117s - loss: 0.0685 - acc: 0.9782 - val_loss: 2.1434 - val_acc: 0.2718
Epoch 15/1000
117s - loss: 0.0663 - acc: 0.9782 - val_loss: 2.1455 - val_acc: 0.2561
Epoch 16/1000
114s - loss: 0.0644 - acc: 0.9793 - val_loss: 2.1218 - val_acc: 0.2690
Epoch 17/1000
111s - loss: 0.0683 - acc: 0.9783 - val_loss: 2.1324 - val_acc: 0.2718
Epoch 18/1000
113s - loss: 0.0668 - acc: 0.9780 - val_loss: 2.0993 - val_acc: 0.2675
Epoch 19/1000
112s - loss: 0.0674 - acc: 0.9777 - val_loss: 2.1305 - val_acc: 0.2518
Epoch 20/1000
111s - loss: 0.0665 - acc: 0.9778 - val_loss: 2.1301 - val_acc: 0.2675
Epoch 21/1000
112s - loss: 0.0658 - acc: 0.9793 - val_loss: 2.1216 - val_acc: 0.2690
Epoch 22/1000
110s - loss: 0.0654 - acc: 0.9789 - val_loss: 2.0911 - val_acc: 0.2675
Epoch 23/1000
110s - loss: 0.0680 - acc: 0.9786 - val_loss: 2.1651 - val_acc: 0.2732
Epoch 24/1000
110s - loss: 0.0701 - acc: 0.9774 - val_loss: 2.1803 - val_acc: 0.2732
Epoch 25/1000
111s - loss: 0.0645 - acc: 0.9786 - val_loss: 2.0880 - val_acc: 0.2761
Epoch 26/1000
111s - loss: 0.0685 - acc: 0.9772 - val_loss: 2.1118 - val_acc: 0.2747
Epoch 27/1000
112s - loss: 0.0646 - acc: 0.9782 - val_loss: 2.0559 - val_acc: 0.2690
Epoch 28/1000
110s - loss: 0.0634 - acc: 0.9789 - val_loss: 2.0677 - val_acc: 0.2747
Epoch 29/1000
110s - loss: 0.0689 - acc: 0.9785 - val_loss: 2.0775 - val_acc: 0.2718
Epoch 30/1000
110s - loss: 0.0658 - acc: 0.9773 - val_loss: 2.0798 - val_acc: 0.2775
Epoch 31/1000
110s - loss: 0.0654 - acc: 0.9783 - val_loss: 2.0569 - val_acc: 0.2675
Epoch 32/1000
110s - loss: 0.0682 - acc: 0.9777 - val_loss: 2.0827 - val_acc: 0.2775
Epoch 33/1000
111s - loss: 0.0651 - acc: 0.9789 - val_loss: 2.0730 - val_acc: 0.2704
Epoch 34/1000
111s - loss: 0.0610 - acc: 0.9791 - val_loss: 2.0460 - val_acc: 0.2775
Epoch 35/1000
110s - loss: 0.0688 - acc: 0.9776 - val_loss: 2.0714 - val_acc: 0.2732
Epoch 36/1000
111s - loss: 0.0656 - acc: 0.9785 - val_loss: 2.1029 - val_acc: 0.2876
Epoch 37/1000
112s - loss: 0.0670 - acc: 0.9794 - val_loss: 2.0474 - val_acc: 0.2747
Epoch 38/1000
112s - loss: 0.0658 - acc: 0.9790 - val_loss: 2.0881 - val_acc: 0.2847
Epoch 39/1000
110s - loss: 0.0657 - acc: 0.9790 - val_loss: 2.0578 - val_acc: 0.2732
Epoch 40/1000
111s - loss: 0.0657 - acc: 0.9793 - val_loss: 2.1131 - val_acc: 0.2818
Epoch 41/1000
111s - loss: 0.0650 - acc: 0.9766 - val_loss: 2.0676 - val_acc: 0.2632
Epoch 42/1000
110s - loss: 0.0654 - acc: 0.9785 - val_loss: 2.0560 - val_acc: 0.2690
Epoch 43/1000
111s - loss: 0.0666 - acc: 0.9778 - val_loss: 2.0555 - val_acc: 0.2690
Epoch 44/1000
112s - loss: 0.0673 - acc: 0.9781 - val_loss: 2.0684 - val_acc: 0.2876
Epoch 45/1000
111s - loss: 0.0660 - acc: 0.9789 - val_loss: 2.0452 - val_acc: 0.2804
Epoch 46/1000
112s - loss: 0.0652 - acc: 0.9789 - val_loss: 2.0274 - val_acc: 0.2804
Epoch 47/1000
113s - loss: 0.0658 - acc: 0.9784 - val_loss: 2.0741 - val_acc: 0.2833
Epoch 48/1000
111s - loss: 0.0665 - acc: 0.9791 - val_loss: 2.0823 - val_acc: 0.2661
Epoch 49/1000
112s - loss: 0.0627 - acc: 0.9793 - val_loss: 2.0158 - val_acc: 0.2818
Epoch 50/1000
112s - loss: 0.0629 - acc: 0.9792 - val_loss: 2.0399 - val_acc: 0.2704
Epoch 51/1000
110s - loss: 0.0638 - acc: 0.9784 - val_loss: 2.0276 - val_acc: 0.2818
Epoch 52/1000
110s - loss: 0.0658 - acc: 0.9780 - val_loss: 2.0289 - val_acc: 0.2732
Epoch 53/1000
110s - loss: 0.0650 - acc: 0.9787 - val_loss: 2.0645 - val_acc: 0.2833
Epoch 54/1000
111s - loss: 0.0668 - acc: 0.9772 - val_loss: 2.0534 - val_acc: 0.2861
Epoch 55/1000
111s - loss: 0.0613 - acc: 0.9788 - val_loss: 2.0038 - val_acc: 0.2933
Epoch 56/1000
110s - loss: 0.0653 - acc: 0.9784 - val_loss: 2.1181 - val_acc: 0.2718
Epoch 57/1000
110s - loss: 0.0641 - acc: 0.9789 - val_loss: 2.0457 - val_acc: 0.2704
Epoch 58/1000
111s - loss: 0.0653 - acc: 0.9786 - val_loss: 2.0324 - val_acc: 0.2833
Epoch 59/1000
110s - loss: 0.0659 - acc: 0.9789 - val_loss: 2.0421 - val_acc: 0.2704
Epoch 60/1000
111s - loss: 0.0672 - acc: 0.9782 - val_loss: 2.0412 - val_acc: 0.2818
Epoch 61/1000
113s - loss: 0.0644 - acc: 0.9776 - val_loss: 2.0458 - val_acc: 0.2890
Epoch 62/1000
112s - loss: 0.0652 - acc: 0.9786 - val_loss: 2.0426 - val_acc: 0.2818
Epoch 63/1000
111s - loss: 0.0638 - acc: 0.9781 - val_loss: 2.0267 - val_acc: 0.2704
Epoch 64/1000
110s - loss: 0.0627 - acc: 0.9791 - val_loss: 2.0264 - val_acc: 0.2833
Epoch 65/1000
113s - loss: 0.0623 - acc: 0.9780 - val_loss: 2.0193 - val_acc: 0.2775
Epoch 66/1000
112s - loss: 0.0666 - acc: 0.9777 - val_loss: 2.0508 - val_acc: 0.2718
Epoch 67/1000
110s - loss: 0.0627 - acc: 0.9783 - val_loss: 2.0241 - val_acc: 0.2790
Epoch 68/1000
112s - loss: 0.0618 - acc: 0.9791 - val_loss: 2.0690 - val_acc: 0.2818
Epoch 69/1000
111s - loss: 0.0635 - acc: 0.9784 - val_loss: 2.0455 - val_acc: 0.2790
Epoch 70/1000
111s - loss: 0.0658 - acc: 0.9779 - val_loss: 2.0518 - val_acc: 0.2690
Epoch 71/1000
112s - loss: 0.0628 - acc: 0.9794 - val_loss: 2.0281 - val_acc: 0.2775
Epoch 72/1000
110s - loss: 0.0633 - acc: 0.9787 - val_loss: 2.0385 - val_acc: 0.2833
Epoch 73/1000
112s - loss: 0.0630 - acc: 0.9797 - val_loss: 2.0198 - val_acc: 0.2761
Epoch 74/1000
113s - loss: 0.0628 - acc: 0.9788 - val_loss: 2.0281 - val_acc: 0.2747
Epoch 75/1000
113s - loss: 0.0664 - acc: 0.9771 - val_loss: 2.0369 - val_acc: 0.2847
Epoch 76/1000
112s - loss: 0.0645 - acc: 0.9786 - val_loss: 2.0354 - val_acc: 0.2833


{"acc": 0.97855177173366792, "loss": -0.29327610911047342, "val_acc_max": 0.29327610911047342, "val_loss_min": 2.003784140121613, "status": "ok", "val_acc": 0.28326180210611512, "loss_": 0.064522580384756584, "epochs_len": 76, "acc_max": 0.9796668172398687, "loss_min": 0.060971445877717814, "val_loss": 2.0354269205756452}

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16080345.ba+  13578660K  12009821K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16080345     rnn-glove+          4                         02:42:50      0:0 

Job 16080345 ("rnn-glove-wikipedia-gigawords") completed on c15-29 at tis dec 6 03:53:33 CET 2016
Starting job 16086901 ("rnn-glove-wikipedia-gigawords") on c13-29 at tis dec 6 15:26:45 CET 2016
Python environment is set up
Copying files to /work/jobs/16086901.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16086901.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16086901.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":4,"rnn_dim":20,"final_dim":100,"words2vec_txt":"$EMBEDDING_PATH"}
Using Theano backend.
[2016-12-06 15:29] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 15:29]     config 'epochs':  (1000)
[2016-12-06 15:29]     config 'epochs_len':  (-1)
[2016-12-06 15:29]     config 'epochs_patience':  (20)
[2016-12-06 15:29]     config 'batch_size':  (64)
[2016-12-06 15:29]     config 'snapshot_size':  (2048)
[2016-12-06 15:29]     config 'random_per_sample':  (32)
[2016-12-06 15:29]     config 'words_dim': 20 (20)
[2016-12-06 15:29]     config 'focus_dim': 4 (4)
[2016-12-06 15:29]     config 'rnn_dim': 20 (20)
[2016-12-06 15:29]     config 'final_dim': 100 (100)
[2016-12-06 15:29]     config 'arg1_len':  (100)
[2016-12-06 15:29]     config 'arg2_len':  (100)
[2016-12-06 15:29]     config 'conn_len':  (10)
[2016-12-06 15:29]     config 'punc_len':  (2)
[2016-12-06 15:29]     config 'words_dropout':  (0.1)
[2016-12-06 15:29]     config 'focus_dropout_W':  (0.33)
[2016-12-06 15:29]     config 'focus_dropout_U':  (0.66)
[2016-12-06 15:29]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 15:29]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 15:29]     config 'final_dropout':  (0.5)
[2016-12-06 15:29]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-06 15:29]     config 'words2vec_bin':  (None)
[2016-12-06 15:29]     config 'words2vec_txt': $EMBEDDING_PATH (None)
[2016-12-06 15:29]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 15:29]   args.train_dir: /work/jobs/16086901.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 15:29]   args.valid_dir: /work/jobs/16086901.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 15:29]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 15:29]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 15:29]   filter_types: None
[2016-12-06 15:29]   filter_senses: None
[2016-12-06 15:29]   filter_fn_name: conn_gt_0
[2016-12-06 15:29]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 4, u'words2vec_txt': u'$EMBEDDING_PATH', u'final_dim': 100, u'rnn_dim': 20}
[2016-12-06 15:29] load dataset for training (/work/jobs/16086901.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
slurmstepd: *** JOB 16086901 ON c13-29 CANCELLED AT 2016-12-06T15:33:03 ***

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16086901.ba+   3810136K   3204651K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16086901     rnn-glove+          4                         00:06:21      0:0 

Job 16086901 ("rnn-glove-wikipedia-gigawords") completed on c13-29 at tis dec 6 15:33:03 CET 2016
Starting job 16086957 ("rnn-glove-wikipedia-gigawords") on c14-30 at tis dec 6 15:36:38 CET 2016
Python environment is set up
Copying files to /work/jobs/16086957.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16086957.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16086957.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"$EMBEDDING_PATH"}
Using Theano backend.
[2016-12-06 15:38] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 15:38]     config 'epochs':  (1000)
[2016-12-06 15:38]     config 'epochs_len':  (-1)
[2016-12-06 15:38]     config 'epochs_patience':  (20)
[2016-12-06 15:38]     config 'batch_size':  (64)
[2016-12-06 15:38]     config 'snapshot_size':  (2048)
[2016-12-06 15:38]     config 'random_per_sample':  (32)
[2016-12-06 15:38]     config 'words_dim': 20 (20)
[2016-12-06 15:38]     config 'focus_dim': 6 (4)
[2016-12-06 15:38]     config 'rnn_dim': 50 (20)
[2016-12-06 15:38]     config 'final_dim': 40 (100)
[2016-12-06 15:38]     config 'arg1_len':  (100)
[2016-12-06 15:38]     config 'arg2_len':  (100)
[2016-12-06 15:38]     config 'conn_len':  (10)
[2016-12-06 15:38]     config 'punc_len':  (2)
[2016-12-06 15:38]     config 'words_dropout':  (0.1)
[2016-12-06 15:38]     config 'focus_dropout_W':  (0.33)
[2016-12-06 15:38]     config 'focus_dropout_U':  (0.66)
[2016-12-06 15:38]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 15:38]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 15:38]     config 'final_dropout':  (0.5)
[2016-12-06 15:38]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-06 15:38]     config 'words2vec_bin':  (None)
[2016-12-06 15:38]     config 'words2vec_txt': $EMBEDDING_PATH (None)
[2016-12-06 15:38]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 15:38]   args.train_dir: /work/jobs/16086957.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 15:38]   args.valid_dir: /work/jobs/16086957.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 15:38]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 15:38]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 15:38]   filter_types: None
[2016-12-06 15:38]   filter_senses: None
[2016-12-06 15:38]   filter_fn_name: conn_gt_0
[2016-12-06 15:38]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 6, u'words2vec_txt': u'$EMBEDDING_PATH', u'final_dim': 40, u'rnn_dim': 50}
[2016-12-06 15:38] load dataset for training (/work/jobs/16086957.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 15:44] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-06 15:44] load dataset for validation (/work/jobs/16086957.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 15:44] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-06 15:44] build indexes
[2016-12-06 15:44]   rel_senses2id: 22, words2id: 43918
[2016-12-06 15:44] Fast version of gensim.models.doc2vec is being used
[2016-12-06 15:44] 'pattern' package found; tag filters are available for English
[2016-12-06 15:44] loading projection weights from $EMBEDDING_PATH
Traceback (most recent call last):
  File "./v34/train.py", line 153, in <module>
    init_weights = load_word2vec(indexes['words2id'], indexes_size['words2id'], words_dim, words2vec_bin, words2vec_txt)
  File "/work/jobs/16086957.d/conll16st-v34-focused-rnns/v34/data_utils.py", line 229, in load_word2vec
    model = word2vec.Word2Vec.load_word2vec_format(words2vec_txt)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/gensim/models/word2vec.py", line 1171, in load_word2vec_format
    with utils.smart_open(fname) as fin:
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 127, in smart_open
    return file_smart_open(parsed_uri.uri_path, mode)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 558, in file_smart_open
    return open(fname, mode)
IOError: [Errno 2] No such file or directory: u'$EMBEDDING_PATH'
> /usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py(558)file_smart_open()
-> return open(fname, mode)
(Pdb) 

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16086957.ba+   5596732K   5105689K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16086957     rnn-glove+          4                         00:08:26      0:0 

Job 16086957 ("rnn-glove-wikipedia-gigawords") completed on c14-30 at tis dec 6 15:45:00 CET 2016
Starting job 16087288 ("rnn-glove-wikipedia-gigawords") on c15-16 at tis dec 6 16:19:50 CET 2016
Python environment is set up
Copying files to /work/jobs/16087288.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16087288.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16087288.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"$EMBEDDING_PATH"}
Using Theano backend.
slurmstepd: *** JOB 16087288 ON c15-16 CANCELLED AT 2016-12-06T16:25:46 ***

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16087288.ba+    572216K     40053K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16087288     rnn-glove+          4                         00:06:00      0:0 

Job 16087288 ("rnn-glove-wikipedia-gigawords") completed on c15-16 at tis dec 6 16:25:47 CET 2016
Starting job 16087366 ("rnn-glove-wikipedia-gigawords") on c16-17 at tis dec 6 16:32:48 CET 2016
Python environment is set up
Copying files to /work/jobs/16087366.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16087366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16087366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"${EMBEDDING_PATH}"}
Using Theano backend.
[2016-12-06 16:34] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 16:34]     config 'epochs':  (1000)
[2016-12-06 16:34]     config 'epochs_len':  (-1)
[2016-12-06 16:34]     config 'epochs_patience':  (20)
[2016-12-06 16:34]     config 'batch_size':  (64)
[2016-12-06 16:34]     config 'snapshot_size':  (2048)
[2016-12-06 16:34]     config 'random_per_sample':  (32)
[2016-12-06 16:34]     config 'words_dim': 20 (20)
[2016-12-06 16:34]     config 'focus_dim': 6 (4)
[2016-12-06 16:34]     config 'rnn_dim': 50 (20)
[2016-12-06 16:34]     config 'final_dim': 40 (100)
[2016-12-06 16:34]     config 'arg1_len':  (100)
[2016-12-06 16:34]     config 'arg2_len':  (100)
[2016-12-06 16:34]     config 'conn_len':  (10)
[2016-12-06 16:34]     config 'punc_len':  (2)
[2016-12-06 16:34]     config 'words_dropout':  (0.1)
[2016-12-06 16:34]     config 'focus_dropout_W':  (0.33)
[2016-12-06 16:34]     config 'focus_dropout_U':  (0.66)
[2016-12-06 16:34]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 16:34]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 16:34]     config 'final_dropout':  (0.5)
[2016-12-06 16:34]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-06 16:34]     config 'words2vec_bin':  (None)
[2016-12-06 16:34]     config 'words2vec_txt': ${EMBEDDING_PATH} (None)
[2016-12-06 16:34]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 16:34]   args.train_dir: /work/jobs/16087366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 16:34]   args.valid_dir: /work/jobs/16087366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 16:34]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 16:34]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 16:34]   filter_types: None
[2016-12-06 16:34]   filter_senses: None
[2016-12-06 16:34]   filter_fn_name: conn_gt_0
[2016-12-06 16:34]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 6, u'words2vec_txt': u'${EMBEDDING_PATH}', u'final_dim': 40, u'rnn_dim': 50}
[2016-12-06 16:34] load dataset for training (/work/jobs/16087366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 16:40] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-06 16:40] load dataset for validation (/work/jobs/16087366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 16:40] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-06 16:40] build indexes
[2016-12-06 16:40]   rel_senses2id: 22, words2id: 43918
[2016-12-06 16:40] Fast version of gensim.models.doc2vec is being used
[2016-12-06 16:40] 'pattern' package found; tag filters are available for English
[2016-12-06 16:40] loading projection weights from ${EMBEDDING_PATH}
Traceback (most recent call last):
  File "./v34/train.py", line 153, in <module>
    init_weights = load_word2vec(indexes['words2id'], indexes_size['words2id'], words_dim, words2vec_bin, words2vec_txt)
  File "/work/jobs/16087366.d/conll16st-v34-focused-rnns/v34/data_utils.py", line 229, in load_word2vec
    model = word2vec.Word2Vec.load_word2vec_format(words2vec_txt)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/gensim/models/word2vec.py", line 1171, in load_word2vec_format
    with utils.smart_open(fname) as fin:
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 127, in smart_open
    return file_smart_open(parsed_uri.uri_path, mode)
  File "/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py", line 558, in file_smart_open
    return open(fname, mode)
IOError: [Errno 2] No such file or directory: u'${EMBEDDING_PATH}'
> /usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/smart_open/smart_open_lib.py(558)file_smart_open()
-> return open(fname, mode)
(Pdb) 

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16087366.ba+   5596700K   5105856K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16087366     rnn-glove+          4                         00:08:13      0:0 

Job 16087366 ("rnn-glove-wikipedia-gigawords") completed on c16-17 at tis dec 6 16:41:00 CET 2016
Starting job 16087546 ("rnn-glove-wikipedia-gigawords") on c15-19 at tis dec 6 16:50:06 CET 2016
Python environment is set up
Copying files to /work/jobs/16087546.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16087546.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"/work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt"}
Using Theano backend.
[2016-12-06 16:52] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 16:52]     config 'epochs':  (1000)
[2016-12-06 16:52]     config 'epochs_len':  (-1)
[2016-12-06 16:52]     config 'epochs_patience':  (20)
[2016-12-06 16:52]     config 'batch_size':  (64)
[2016-12-06 16:52]     config 'snapshot_size':  (2048)
[2016-12-06 16:52]     config 'random_per_sample':  (32)
[2016-12-06 16:52]     config 'words_dim': 20 (20)
[2016-12-06 16:52]     config 'focus_dim': 6 (4)
[2016-12-06 16:52]     config 'rnn_dim': 50 (20)
[2016-12-06 16:52]     config 'final_dim': 40 (100)
[2016-12-06 16:52]     config 'arg1_len':  (100)
[2016-12-06 16:52]     config 'arg2_len':  (100)
[2016-12-06 16:52]     config 'conn_len':  (10)
[2016-12-06 16:52]     config 'punc_len':  (2)
[2016-12-06 16:52]     config 'words_dropout':  (0.1)
[2016-12-06 16:52]     config 'focus_dropout_W':  (0.33)
[2016-12-06 16:52]     config 'focus_dropout_U':  (0.66)
[2016-12-06 16:52]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 16:52]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 16:52]     config 'final_dropout':  (0.5)
[2016-12-06 16:52]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-06 16:52]     config 'words2vec_bin':  (None)
[2016-12-06 16:52]     config 'words2vec_txt': /work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-06 16:52]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 16:52]   args.train_dir: /work/jobs/16087546.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 16:52]   args.valid_dir: /work/jobs/16087546.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 16:52]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 16:52]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 16:52]   filter_types: None
[2016-12-06 16:52]   filter_senses: None
[2016-12-06 16:52]   filter_fn_name: conn_gt_0
[2016-12-06 16:52]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 6, u'words2vec_txt': u'/work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt', u'final_dim': 40, u'rnn_dim': 50}
[2016-12-06 16:52] load dataset for training (/work/jobs/16087546.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 16:58] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-06 16:58] load dataset for validation (/work/jobs/16087546.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 16:59] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-06 16:59] build indexes
[2016-12-06 16:59]   rel_senses2id: 22, words2id: 43918
[2016-12-06 16:59] Fast version of gensim.models.doc2vec is being used
[2016-12-06 16:59] 'pattern' package found; tag filters are available for English
[2016-12-06 16:59] loading projection weights from /work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 16:59] Fast version of gensim.models.word2vec is being used
[2016-12-06 16:59] consider setting layer size to a multiple of 4 for greater performance
[2016-12-06 16:59] loaded (400000, 50) matrix from /work/jobs/16087546.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 16:59] build model
[2016-12-06 17:00]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-06 17:00]     config 'optimizer':  (adam)
[2016-12-06 17:00] initialize weights
[2016-12-06 17:00] prepare snapshots
[2016-12-06 17:00] train model
/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/training.py:1397: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
/var/spool/slurmd/job16087546/slurm_script: rad 62: 20564 Dödad                  ./v34/train.py $MODEL_STORE_PATH $DATA_BASE_PATH-train $DATA_BASE_PATH-dev --clean "$CONFIG"

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16087546.ba+  18262168K  16694054K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16087546     rnn-glove+          4                         02:54:52      0:0 

Job 16087546 ("rnn-glove-wikipedia-gigawords") completed on c15-19 at tis dec 6 19:44:55 CET 2016
slurmstepd: Exceeded step memory limit at some point.
Starting job 16090366 ("rnn-glove-wikipedia-gigawords") on c14-33 at tis dec 6 23:05:28 CET 2016
Python environment is set up
Copying files to /work/jobs/16090366.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16090366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"/work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt"}
Using Theano backend.
[2016-12-06 23:11] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-06 23:11]     config 'epochs':  (1000)
[2016-12-06 23:11]     config 'epochs_len':  (-1)
[2016-12-06 23:11]     config 'epochs_patience':  (20)
[2016-12-06 23:11]     config 'batch_size':  (64)
[2016-12-06 23:11]     config 'snapshot_size':  (2048)
[2016-12-06 23:11]     config 'random_per_sample':  (32)
[2016-12-06 23:11]     config 'words_dim': 20 (20)
[2016-12-06 23:11]     config 'focus_dim': 6 (4)
[2016-12-06 23:11]     config 'rnn_dim': 50 (20)
[2016-12-06 23:11]     config 'final_dim': 40 (100)
[2016-12-06 23:11]     config 'arg1_len':  (100)
[2016-12-06 23:11]     config 'arg2_len':  (100)
[2016-12-06 23:11]     config 'conn_len':  (10)
[2016-12-06 23:11]     config 'punc_len':  (2)
[2016-12-06 23:11]     config 'words_dropout':  (0.1)
[2016-12-06 23:11]     config 'focus_dropout_W':  (0.33)
[2016-12-06 23:11]     config 'focus_dropout_U':  (0.66)
[2016-12-06 23:11]     config 'rnn_dropout_W':  (0.33)
[2016-12-06 23:11]     config 'rnn_dropout_U':  (0.33)
[2016-12-06 23:11]     config 'final_dropout':  (0.5)
[2016-12-06 23:11]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-06 23:11]     config 'words2vec_bin':  (None)
[2016-12-06 23:11]     config 'words2vec_txt': /work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-06 23:11]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-06 23:11]   args.train_dir: /work/jobs/16090366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-06 23:11]   args.valid_dir: /work/jobs/16090366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-06 23:11]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-06 23:11]   os.getenv("THEANO_FLAGS"): None
[2016-12-06 23:11]   filter_types: None
[2016-12-06 23:11]   filter_senses: None
[2016-12-06 23:11]   filter_fn_name: conn_gt_0
[2016-12-06 23:11]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 6, u'words2vec_txt': u'/work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt', u'final_dim': 40, u'rnn_dim': 50}
[2016-12-06 23:11] load dataset for training (/work/jobs/16090366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-06 23:17] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-06 23:17] load dataset for validation (/work/jobs/16090366.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-06 23:17] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-06 23:17] build indexes
[2016-12-06 23:17]   rel_senses2id: 22, words2id: 43918
[2016-12-06 23:17] Fast version of gensim.models.doc2vec is being used
[2016-12-06 23:17] 'pattern' package found; tag filters are available for English
[2016-12-06 23:17] loading projection weights from /work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 23:17] Fast version of gensim.models.word2vec is being used
[2016-12-06 23:17] consider setting layer size to a multiple of 4 for greater performance
[2016-12-06 23:18] loaded (400000, 50) matrix from /work/jobs/16090366.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-06 23:18] build model
[2016-12-06 23:18]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-06 23:18]     config 'optimizer':  (adam)
[2016-12-06 23:18] initialize weights
[2016-12-06 23:18] prepare snapshots
[2016-12-06 23:18] train model
/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/training.py:1397: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
/var/spool/slurmd/job16090366/slurm_script: rad 62: 13783 Dödad                  ./v34/train.py $MODEL_STORE_PATH $DATA_BASE_PATH-train $DATA_BASE_PATH-dev --clean "$CONFIG"

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16090366.ba+  26871072K  25162615K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16090366     rnn-glove+          6                         05:52:24      0:0 

Job 16090366 ("rnn-glove-wikipedia-gigawords") completed on c14-33 at ons dec 7 04:57:49 CET 2016
slurmstepd: Exceeded step memory limit at some point.
slurmstepd: Exceeded job memory limit at some point.
Starting job 16098752 ("rnn-glove-wikipedia-gigawords") on c31-15 at ons dec 7 22:32:26 CET 2016
Python environment is set up
Copying files to /work/jobs/16098752.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16098752.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"filter_fn_name":"conn_gt_0","words_dim":20,"focus_dim":6,"rnn_dim":50,"final_dim":40,"words2vec_txt":"/work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt"}
Using Theano backend.
[2016-12-07 22:34] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-07 22:34]     config 'epochs':  (1000)
[2016-12-07 22:34]     config 'epochs_len':  (-1)
[2016-12-07 22:34]     config 'epochs_patience':  (20)
[2016-12-07 22:34]     config 'batch_size':  (64)
[2016-12-07 22:34]     config 'snapshot_size':  (2048)
[2016-12-07 22:34]     config 'random_per_sample':  (32)
[2016-12-07 22:34]     config 'words_dim': 20 (20)
[2016-12-07 22:34]     config 'focus_dim': 6 (4)
[2016-12-07 22:34]     config 'rnn_dim': 50 (20)
[2016-12-07 22:34]     config 'final_dim': 40 (100)
[2016-12-07 22:34]     config 'arg1_len':  (100)
[2016-12-07 22:34]     config 'arg2_len':  (100)
[2016-12-07 22:34]     config 'conn_len':  (10)
[2016-12-07 22:34]     config 'punc_len':  (2)
[2016-12-07 22:34]     config 'words_dropout':  (0.1)
[2016-12-07 22:34]     config 'focus_dropout_W':  (0.33)
[2016-12-07 22:34]     config 'focus_dropout_U':  (0.66)
[2016-12-07 22:34]     config 'rnn_dropout_W':  (0.33)
[2016-12-07 22:34]     config 'rnn_dropout_U':  (0.33)
[2016-12-07 22:34]     config 'final_dropout':  (0.5)
[2016-12-07 22:34]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-07 22:34]     config 'words2vec_bin':  (None)
[2016-12-07 22:34]     config 'words2vec_txt': /work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-07 22:34]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-07 22:34]   args.train_dir: /work/jobs/16098752.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-07 22:34]   args.valid_dir: /work/jobs/16098752.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-07 22:34]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-07 22:34]   os.getenv("THEANO_FLAGS"): None
[2016-12-07 22:34]   filter_types: None
[2016-12-07 22:34]   filter_senses: None
[2016-12-07 22:34]   filter_fn_name: conn_gt_0
[2016-12-07 22:34]   config: {u'words_dim': 20, u'filter_fn_name': u'conn_gt_0', u'focus_dim': 6, u'words2vec_txt': u'/work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt', u'final_dim': 40, u'rnn_dim': 50}
[2016-12-07 22:34] load dataset for training (/work/jobs/16098752.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-07 22:38] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-07 22:38] load dataset for validation (/work/jobs/16098752.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-07 22:38] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-07 22:38] build indexes
[2016-12-07 22:38]   rel_senses2id: 22, words2id: 43918
[2016-12-07 22:38] Fast version of gensim.models.doc2vec is being used
[2016-12-07 22:38] 'pattern' package found; tag filters are available for English
[2016-12-07 22:38] loading projection weights from /work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-07 22:38] Fast version of gensim.models.word2vec is being used
[2016-12-07 22:38] consider setting layer size to a multiple of 4 for greater performance
[2016-12-07 22:38] loaded (400000, 50) matrix from /work/jobs/16098752.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-07 22:38] build model
[2016-12-07 22:39]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-07 22:39]     config 'optimizer':  (adam)
[2016-12-07 22:39] initialize weights
[2016-12-07 22:39] prepare snapshots
[2016-12-07 22:39] train model
/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/training.py:1397: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
[2016-12-08 03:38] training finished
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
arg1_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
arg2_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
conn_ids (InputLayer)              (None, 10)          0                                            
____________________________________________________________________________________________________
punc_ids (InputLayer)              (None, 2)           0                                            
____________________________________________________________________________________________________
shared_emb (Embedding)             multiple            878360      arg1_ids[0][0]                   
                                                                   arg2_ids[0][0]                   
                                                                   conn_ids[0][0]                   
                                                                   punc_ids[0][0]                   
____________________________________________________________________________________________________
gru_1 (GRU)                        (None, 100, 6)      486         shared_emb[0][0]                 
____________________________________________________________________________________________________
gru_15 (GRU)                       (None, 10, 6)       486         shared_emb[2][0]                 
____________________________________________________________________________________________________
gru_22 (GRU)                       (None, 2, 6)        486         shared_emb[3][0]                 
____________________________________________________________________________________________________
gru_8 (GRU)                        (None, 100, 6)      486         shared_emb[1][0]                 
____________________________________________________________________________________________________
timedistributed_1 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_10 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_11 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_12 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_13 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_14 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_15 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_16 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_17 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_18 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_19 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_2 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_20 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_21 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_22 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_23 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_24 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_3 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_4 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_5 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_6 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_7 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_8 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_9 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
merge_1 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_1[0][0]          
____________________________________________________________________________________________________
merge_10 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_10[0][0]         
____________________________________________________________________________________________________
merge_11 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_11[0][0]         
____________________________________________________________________________________________________
merge_12 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_12[0][0]         
____________________________________________________________________________________________________
merge_13 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_13[0][0]         
____________________________________________________________________________________________________
merge_14 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_14[0][0]         
____________________________________________________________________________________________________
merge_15 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_15[0][0]         
____________________________________________________________________________________________________
merge_16 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_16[0][0]         
____________________________________________________________________________________________________
merge_17 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_17[0][0]         
____________________________________________________________________________________________________
merge_18 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_18[0][0]         
____________________________________________________________________________________________________
merge_19 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_19[0][0]         
____________________________________________________________________________________________________
merge_2 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_2[0][0]          
____________________________________________________________________________________________________
merge_20 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_20[0][0]         
____________________________________________________________________________________________________
merge_21 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_21[0][0]         
____________________________________________________________________________________________________
merge_22 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_22[0][0]         
____________________________________________________________________________________________________
merge_23 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_23[0][0]         
____________________________________________________________________________________________________
merge_24 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_24[0][0]         
____________________________________________________________________________________________________
merge_3 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_3[0][0]          
____________________________________________________________________________________________________
merge_4 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_4[0][0]          
____________________________________________________________________________________________________
merge_5 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_5[0][0]          
____________________________________________________________________________________________________
merge_6 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_6[0][0]          
____________________________________________________________________________________________________
merge_7 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_7[0][0]          
____________________________________________________________________________________________________
merge_8 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_8[0][0]          
____________________________________________________________________________________________________
merge_9 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_9[0][0]          
____________________________________________________________________________________________________
gru_10 (GRU)                       (None, 50)          10650       merge_8[0][0]                    
____________________________________________________________________________________________________
gru_11 (GRU)                       (None, 50)          10650       merge_9[0][0]                    
____________________________________________________________________________________________________
gru_12 (GRU)                       (None, 50)          10650       merge_10[0][0]                   
____________________________________________________________________________________________________
gru_13 (GRU)                       (None, 50)          10650       merge_11[0][0]                   
____________________________________________________________________________________________________
gru_14 (GRU)                       (None, 50)          10650       merge_12[0][0]                   
____________________________________________________________________________________________________
gru_16 (GRU)                       (None, 50)          10650       merge_13[0][0]                   
____________________________________________________________________________________________________
gru_17 (GRU)                       (None, 50)          10650       merge_14[0][0]                   
____________________________________________________________________________________________________
gru_18 (GRU)                       (None, 50)          10650       merge_15[0][0]                   
____________________________________________________________________________________________________
gru_19 (GRU)                       (None, 50)          10650       merge_16[0][0]                   
____________________________________________________________________________________________________
gru_2 (GRU)                        (None, 50)          10650       merge_1[0][0]                    
____________________________________________________________________________________________________
gru_20 (GRU)                       (None, 50)          10650       merge_17[0][0]                   
____________________________________________________________________________________________________
gru_21 (GRU)                       (None, 50)          10650       merge_18[0][0]                   
____________________________________________________________________________________________________
gru_23 (GRU)                       (None, 50)          10650       merge_19[0][0]                   
____________________________________________________________________________________________________
gru_24 (GRU)                       (None, 50)          10650       merge_20[0][0]                   
____________________________________________________________________________________________________
gru_25 (GRU)                       (None, 50)          10650       merge_21[0][0]                   
____________________________________________________________________________________________________
gru_26 (GRU)                       (None, 50)          10650       merge_22[0][0]                   
____________________________________________________________________________________________________
gru_27 (GRU)                       (None, 50)          10650       merge_23[0][0]                   
____________________________________________________________________________________________________
gru_28 (GRU)                       (None, 50)          10650       merge_24[0][0]                   
____________________________________________________________________________________________________
gru_3 (GRU)                        (None, 50)          10650       merge_2[0][0]                    
____________________________________________________________________________________________________
gru_4 (GRU)                        (None, 50)          10650       merge_3[0][0]                    
____________________________________________________________________________________________________
gru_5 (GRU)                        (None, 50)          10650       merge_4[0][0]                    
____________________________________________________________________________________________________
gru_6 (GRU)                        (None, 50)          10650       merge_5[0][0]                    
____________________________________________________________________________________________________
gru_7 (GRU)                        (None, 50)          10650       merge_6[0][0]                    
____________________________________________________________________________________________________
gru_9 (GRU)                        (None, 50)          10650       merge_7[0][0]                    
____________________________________________________________________________________________________
merge_25 (Merge)                   (None, 1200)        0           gru_2[0][0]                      
                                                                   gru_3[0][0]                      
                                                                   gru_4[0][0]                      
                                                                   gru_5[0][0]                      
                                                                   gru_6[0][0]                      
                                                                   gru_7[0][0]                      
                                                                   gru_9[0][0]                      
                                                                   gru_10[0][0]                     
                                                                   gru_11[0][0]                     
                                                                   gru_12[0][0]                     
                                                                   gru_13[0][0]                     
                                                                   gru_14[0][0]                     
                                                                   gru_16[0][0]                     
                                                                   gru_17[0][0]                     
                                                                   gru_18[0][0]                     
                                                                   gru_19[0][0]                     
                                                                   gru_20[0][0]                     
                                                                   gru_21[0][0]                     
                                                                   gru_23[0][0]                     
                                                                   gru_24[0][0]                     
                                                                   gru_25[0][0]                     
                                                                   gru_26[0][0]                     
                                                                   gru_27[0][0]                     
                                                                   gru_28[0][0]                     
____________________________________________________________________________________________________
dense_1 (Dense)                    (None, 40)          48040       merge_25[0][0]                   
____________________________________________________________________________________________________
srelu_1 (SReLU)                    (None, 40)          160         dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 40)          0           srelu_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 22)          902         dropout_1[0][0]                  
____________________________________________________________________________________________________
rsenses (Activation)               (None, 22)          0           dense_2[0][0]                    
====================================================================================================
Total params: 1185006
____________________________________________________________________________________________________
Epoch 1/1000
641s - loss: 0.2390 - acc: 0.9678 - val_loss: 3.3570 - val_acc: 0.0299
Epoch 2/1000
635s - loss: 0.1087 - acc: 0.9712 - val_loss: 2.5777 - val_acc: 0.1072
Epoch 3/1000
638s - loss: 0.0973 - acc: 0.9722 - val_loss: 2.4563 - val_acc: 0.1764
Epoch 4/1000
634s - loss: 0.0981 - acc: 0.9720 - val_loss: 2.7402 - val_acc: 0.1330
Epoch 5/1000
637s - loss: 0.0894 - acc: 0.9729 - val_loss: 2.3244 - val_acc: 0.1927
Epoch 6/1000
640s - loss: 0.0861 - acc: 0.9735 - val_loss: 2.2215 - val_acc: 0.2483
Epoch 7/1000
595s - loss: 0.0865 - acc: 0.9737 - val_loss: 2.2156 - val_acc: 0.2239
Epoch 8/1000
241s - loss: 0.0811 - acc: 0.9741 - val_loss: 2.5177 - val_acc: 0.2307
Epoch 9/1000
240s - loss: 0.0799 - acc: 0.9734 - val_loss: 2.2871 - val_acc: 0.2727
Epoch 10/1000
241s - loss: 0.0772 - acc: 0.9756 - val_loss: 2.2053 - val_acc: 0.2564
Epoch 11/1000
242s - loss: 0.0828 - acc: 0.9737 - val_loss: 2.5858 - val_acc: 0.2157
Epoch 12/1000
242s - loss: 0.0791 - acc: 0.9740 - val_loss: 2.4037 - val_acc: 0.2239
Epoch 13/1000
242s - loss: 0.0768 - acc: 0.9757 - val_loss: 2.4148 - val_acc: 0.2429
Epoch 14/1000
240s - loss: 0.0778 - acc: 0.9760 - val_loss: 2.2628 - val_acc: 0.2632
Epoch 15/1000
241s - loss: 0.0812 - acc: 0.9744 - val_loss: 2.9830 - val_acc: 0.1859
Epoch 16/1000
243s - loss: 0.0739 - acc: 0.9744 - val_loss: 2.2946 - val_acc: 0.1655
Epoch 17/1000
242s - loss: 0.0732 - acc: 0.9746 - val_loss: 2.2822 - val_acc: 0.2754
Epoch 18/1000
242s - loss: 0.0765 - acc: 0.9748 - val_loss: 2.1686 - val_acc: 0.2863
Epoch 19/1000
241s - loss: 0.0795 - acc: 0.9743 - val_loss: 2.2328 - val_acc: 0.2700
Epoch 20/1000
241s - loss: 0.0747 - acc: 0.9752 - val_loss: 2.2722 - val_acc: 0.2700
Epoch 21/1000
241s - loss: 0.0747 - acc: 0.9744 - val_loss: 2.3160 - val_acc: 0.1601
Epoch 22/1000
241s - loss: 0.0769 - acc: 0.9758 - val_loss: 2.3473 - val_acc: 0.2673
Epoch 23/1000
241s - loss: 0.0771 - acc: 0.9753 - val_loss: 2.1395 - val_acc: 0.2836
Epoch 24/1000
240s - loss: 0.0748 - acc: 0.9762 - val_loss: 2.2769 - val_acc: 0.2659
Epoch 25/1000
240s - loss: 0.0759 - acc: 0.9747 - val_loss: 2.2191 - val_acc: 0.2374
Epoch 26/1000
245s - loss: 0.0714 - acc: 0.9755 - val_loss: 2.2821 - val_acc: 0.2456
Epoch 27/1000
252s - loss: 0.0742 - acc: 0.9759 - val_loss: 2.2663 - val_acc: 0.2687
Epoch 28/1000
252s - loss: 0.0758 - acc: 0.9750 - val_loss: 2.2528 - val_acc: 0.2795
Epoch 29/1000
253s - loss: 0.0728 - acc: 0.9763 - val_loss: 2.5539 - val_acc: 0.2415
Epoch 30/1000
253s - loss: 0.0709 - acc: 0.9770 - val_loss: 2.2346 - val_acc: 0.2687
Epoch 31/1000
253s - loss: 0.0755 - acc: 0.9753 - val_loss: 2.2246 - val_acc: 0.2754
Epoch 32/1000
254s - loss: 0.0717 - acc: 0.9757 - val_loss: 2.2037 - val_acc: 0.2795
Epoch 33/1000
254s - loss: 0.0706 - acc: 0.9767 - val_loss: 2.1649 - val_acc: 0.2836
Epoch 34/1000
254s - loss: 0.0700 - acc: 0.9758 - val_loss: 2.1858 - val_acc: 0.2822
Epoch 35/1000
254s - loss: 0.0729 - acc: 0.9765 - val_loss: 2.1196 - val_acc: 0.2917
Epoch 36/1000
254s - loss: 0.0752 - acc: 0.9748 - val_loss: 2.1822 - val_acc: 0.2809
Epoch 37/1000
255s - loss: 0.0716 - acc: 0.9759 - val_loss: 2.0931 - val_acc: 0.2877
Epoch 38/1000
254s - loss: 0.0694 - acc: 0.9763 - val_loss: 2.3425 - val_acc: 0.2578
Epoch 39/1000
254s - loss: 0.0710 - acc: 0.9750 - val_loss: 2.0961 - val_acc: 0.2904
Epoch 40/1000
255s - loss: 0.0714 - acc: 0.9770 - val_loss: 2.1652 - val_acc: 0.2822
Epoch 41/1000
253s - loss: 0.0707 - acc: 0.9766 - val_loss: 2.1412 - val_acc: 0.2890
Epoch 42/1000
253s - loss: 0.0703 - acc: 0.9762 - val_loss: 2.1535 - val_acc: 0.2754
Epoch 43/1000
253s - loss: 0.0741 - acc: 0.9750 - val_loss: 2.1533 - val_acc: 0.2687
Epoch 44/1000
253s - loss: 0.0746 - acc: 0.9751 - val_loss: 2.1878 - val_acc: 0.2836
Epoch 45/1000
253s - loss: 0.0747 - acc: 0.9755 - val_loss: 2.1703 - val_acc: 0.2836
Epoch 46/1000
253s - loss: 0.0704 - acc: 0.9772 - val_loss: 2.1405 - val_acc: 0.2782
Epoch 47/1000
253s - loss: 0.0700 - acc: 0.9756 - val_loss: 2.1649 - val_acc: 0.2849
Epoch 48/1000
253s - loss: 0.0737 - acc: 0.9758 - val_loss: 2.1212 - val_acc: 0.2863
Epoch 49/1000
253s - loss: 0.0721 - acc: 0.9758 - val_loss: 2.3068 - val_acc: 0.2632
Epoch 50/1000
253s - loss: 0.0711 - acc: 0.9763 - val_loss: 2.1229 - val_acc: 0.2334
Epoch 51/1000
253s - loss: 0.0782 - acc: 0.9746 - val_loss: 2.3351 - val_acc: 0.2537
Epoch 52/1000
253s - loss: 0.0718 - acc: 0.9753 - val_loss: 2.2840 - val_acc: 0.2646
Epoch 53/1000
253s - loss: 0.0741 - acc: 0.9755 - val_loss: 2.1838 - val_acc: 0.2212
Epoch 54/1000
253s - loss: 0.0766 - acc: 0.9747 - val_loss: 2.1945 - val_acc: 0.2714
Epoch 55/1000
254s - loss: 0.0714 - acc: 0.9764 - val_loss: 2.2318 - val_acc: 0.2877
Epoch 56/1000
254s - loss: 0.0722 - acc: 0.9755 - val_loss: 2.1083 - val_acc: 0.2782
Epoch 57/1000
253s - loss: 0.0732 - acc: 0.9766 - val_loss: 2.2546 - val_acc: 0.2687
Epoch 58/1000
254s - loss: 0.0716 - acc: 0.9757 - val_loss: 2.1923 - val_acc: 0.2809


{"acc": 0.97565350391482575, "loss": -0.29172320217096337, "val_acc_max": 0.29172320217096337, "val_loss_min": 2.0931486001331736, "status": "ok", "val_acc": 0.28086838534599728, "loss_": 0.071559796195107564, "epochs_len": 58, "acc_max": 0.97721491810929684, "loss_min": 0.069350268737988843, "val_loss": 2.1923235607923615}

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16098752.ba+  26822888K  25109118K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16098752     rnn-glove+          6                         05:06:01      0:0 

Job 16098752 ("rnn-glove-wikipedia-gigawords") completed on c31-15 at tor dec 8 03:38:25 CET 2016
slurmstepd: Exceeded step memory limit at some point.
Starting job 16167505 ("rnn-glove-wikipedia-gigawords") on c17-20 at ons dec 14 21:15:22 CET 2016
Python environment is set up
Copying files to /work/jobs/16167505.d...
We are now in conll16st-v34-focused-rnns
Starting RNN run
NAME: rnn-glove-wikipedia-gigawords
LOCAL_BASE_DIR: /usit/abel/u1/jimmycallin/
EMBEDDING_PATH: /work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
DATA_BASE_PATH: /work/jobs/16167505.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16
MODEL_STORE_PATH: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
CONFIG: --config={"words2vec_bin": null, "words_dim": 20.0, "filter_fn_name": "conn_gt_0", "focus_dim": 6.0, "random_per_sample": 24.0, "final_dropout": 0.01608656108471007, "epochs": 200, "words2vec_txt": "/work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt", "focus_dropout_W": 0.4850461135349744, "rnn_dim": 50.0, "focus_dropout_U": 0.18210894621865603, "epochs_len": -1, "final_dim": 40.0, "epochs_patience": 10, "rnn_dropout_W": 0.16649459724958682, "words_dropout": 0.3543889040084549, "rnn_dropout_U": 0.4899141021546136}
Using Theano backend.
[2016-12-14 21:24] configuration (/usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords)
[2016-12-14 21:24]     config 'epochs': 200 (1000)
[2016-12-14 21:24]     config 'epochs_len': -1 (-1)
[2016-12-14 21:24]     config 'epochs_patience': 10 (20)
[2016-12-14 21:24]     config 'batch_size':  (64)
[2016-12-14 21:24]     config 'snapshot_size':  (2048)
[2016-12-14 21:24]     config 'random_per_sample': 24.0 (32)
[2016-12-14 21:24]     config 'words_dim': 20.0 (20)
[2016-12-14 21:24]     config 'focus_dim': 6.0 (4)
[2016-12-14 21:24]     config 'rnn_dim': 50.0 (20)
[2016-12-14 21:24]     config 'final_dim': 40.0 (100)
[2016-12-14 21:24]     config 'arg1_len':  (100)
[2016-12-14 21:24]     config 'arg2_len':  (100)
[2016-12-14 21:24]     config 'conn_len':  (10)
[2016-12-14 21:24]     config 'punc_len':  (2)
[2016-12-14 21:24]     config 'words_dropout': 0.354388904008 (0.1)
[2016-12-14 21:24]     config 'focus_dropout_W': 0.485046113535 (0.33)
[2016-12-14 21:24]     config 'focus_dropout_U': 0.182108946219 (0.66)
[2016-12-14 21:24]     config 'rnn_dropout_W': 0.16649459725 (0.33)
[2016-12-14 21:24]     config 'rnn_dropout_U': 0.489914102155 (0.33)
[2016-12-14 21:24]     config 'final_dropout': 0.0160865610847 (0.5)
[2016-12-14 21:24]     config 'filter_fn_name': conn_gt_0 (conn_eq_0)
[2016-12-14 21:24]     config 'words2vec_bin': None (None)
[2016-12-14 21:24]     config 'words2vec_txt': /work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt (None)
[2016-12-14 21:24]   args.experiment_dir: /usit/abel/u1/jimmycallin//models/rnn-glove-wikipedia-gigawords
[2016-12-14 21:24]   args.train_dir: /work/jobs/16167505.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train
[2016-12-14 21:24]   args.valid_dir: /work/jobs/16167505.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev
[2016-12-14 21:24]   K._config: {u'image_dim_ordering': u'tf', u'backend': u'theano', u'floatx': u'float32', u'epsilon': 1e-07}
[2016-12-14 21:24]   os.getenv("THEANO_FLAGS"): None
[2016-12-14 21:24]   filter_types: None
[2016-12-14 21:24]   filter_senses: None
[2016-12-14 21:24]   filter_fn_name: conn_gt_0
[2016-12-14 21:24]   config: {u'words_dim': 20.0, u'random_per_sample': 24.0, u'focus_dim': 6.0, u'filter_fn_name': u'conn_gt_0', u'final_dropout': 0.01608656108471007, u'rnn_dropout_W': 0.16649459724958682, u'epochs': 200, u'epochs_len': -1, u'focus_dropout_W': 0.4850461135349744, u'words2vec_txt': u'/work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt', u'words2vec_bin': None, u'final_dim': 40.0, u'rnn_dropout_U': 0.4899141021546136, u'focus_dropout_U': 0.18210894621865603, u'rnn_dim': 50.0, u'words_dropout': 0.3543889040084549, u'epochs_patience': 10}
[2016-12-14 21:24] load dataset for training (/work/jobs/16167505.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-train)
[2016-12-14 21:34] lang: ?, doc_ids: 1756, words: 933049, rel_ids: 17289, relation tokens: 676659
[2016-12-14 21:34] load dataset for validation (/work/jobs/16167505.d/resources/conll16st-en-zh-dev-train-test_LDC2016E50/conll16st-en-03-29-16-dev)
[2016-12-14 21:35] lang: ?, doc_ids: 79, words: 39712, rel_ids: 737, relation tokens: 28745
[2016-12-14 21:35] build indexes
[2016-12-14 21:35]   rel_senses2id: 22, words2id: 43918
[2016-12-14 21:35] Fast version of gensim.models.doc2vec is being used
[2016-12-14 21:35] 'pattern' package found; tag filters are available for English
[2016-12-14 21:35] loading projection weights from /work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-14 21:35] Fast version of gensim.models.word2vec is being used
[2016-12-14 21:35] consider setting layer size to a multiple of 4 for greater performance
[2016-12-14 21:36] loaded (400000, 50) matrix from /work/jobs/16167505.d/resources//word_embeddings/precompiled/glove/glove.6B.50d.txt
[2016-12-14 21:36] build model
[2016-12-14 21:36]     config 'rsenses_loss':  (categorical_crossentropy)
[2016-12-14 21:36]     config 'optimizer':  (adam)
[2016-12-14 21:36] initialize weights
[2016-12-14 21:36] prepare snapshots
[2016-12-14 21:36] train model
/usit/abel/u1/jimmycallin/miniconda2/envs/rnn/lib/python2.7/site-packages/keras/engine/training.py:1397: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.
  warnings.warn('Epoch comprised more than '
[2016-12-15 00:04] training finished
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
arg1_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
arg2_ids (InputLayer)              (None, 100)         0                                            
____________________________________________________________________________________________________
conn_ids (InputLayer)              (None, 10)          0                                            
____________________________________________________________________________________________________
punc_ids (InputLayer)              (None, 2)           0                                            
____________________________________________________________________________________________________
shared_emb (Embedding)             multiple            878360      arg1_ids[0][0]                   
                                                                   arg2_ids[0][0]                   
                                                                   conn_ids[0][0]                   
                                                                   punc_ids[0][0]                   
____________________________________________________________________________________________________
gru_1 (GRU)                        (None, 100, 6)      486         shared_emb[0][0]                 
____________________________________________________________________________________________________
gru_15 (GRU)                       (None, 10, 6)       486         shared_emb[2][0]                 
____________________________________________________________________________________________________
gru_22 (GRU)                       (None, 2, 6)        486         shared_emb[3][0]                 
____________________________________________________________________________________________________
gru_8 (GRU)                        (None, 100, 6)      486         shared_emb[1][0]                 
____________________________________________________________________________________________________
timedistributed_1 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_10 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_11 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_12 (TimeDistributed(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_13 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_14 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_15 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_16 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_17 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_18 (TimeDistributed(None, 10, 20)      0           gru_15[0][0]                     
____________________________________________________________________________________________________
timedistributed_19 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_2 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_20 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_21 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_22 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_23 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_24 (TimeDistributed(None, 2, 20)       0           gru_22[0][0]                     
____________________________________________________________________________________________________
timedistributed_3 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_4 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_5 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_6 (TimeDistributed)(None, 100, 20)     0           gru_1[0][0]                      
____________________________________________________________________________________________________
timedistributed_7 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_8 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
timedistributed_9 (TimeDistributed)(None, 100, 20)     0           gru_8[0][0]                      
____________________________________________________________________________________________________
merge_1 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_1[0][0]          
____________________________________________________________________________________________________
merge_10 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_10[0][0]         
____________________________________________________________________________________________________
merge_11 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_11[0][0]         
____________________________________________________________________________________________________
merge_12 (Merge)                   (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_12[0][0]         
____________________________________________________________________________________________________
merge_13 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_13[0][0]         
____________________________________________________________________________________________________
merge_14 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_14[0][0]         
____________________________________________________________________________________________________
merge_15 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_15[0][0]         
____________________________________________________________________________________________________
merge_16 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_16[0][0]         
____________________________________________________________________________________________________
merge_17 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_17[0][0]         
____________________________________________________________________________________________________
merge_18 (Merge)                   (None, 10, 20)      0           shared_emb[2][0]                 
                                                                   timedistributed_18[0][0]         
____________________________________________________________________________________________________
merge_19 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_19[0][0]         
____________________________________________________________________________________________________
merge_2 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_2[0][0]          
____________________________________________________________________________________________________
merge_20 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_20[0][0]         
____________________________________________________________________________________________________
merge_21 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_21[0][0]         
____________________________________________________________________________________________________
merge_22 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_22[0][0]         
____________________________________________________________________________________________________
merge_23 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_23[0][0]         
____________________________________________________________________________________________________
merge_24 (Merge)                   (None, 2, 20)       0           shared_emb[3][0]                 
                                                                   timedistributed_24[0][0]         
____________________________________________________________________________________________________
merge_3 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_3[0][0]          
____________________________________________________________________________________________________
merge_4 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_4[0][0]          
____________________________________________________________________________________________________
merge_5 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_5[0][0]          
____________________________________________________________________________________________________
merge_6 (Merge)                    (None, 100, 20)     0           shared_emb[0][0]                 
                                                                   timedistributed_6[0][0]          
____________________________________________________________________________________________________
merge_7 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_7[0][0]          
____________________________________________________________________________________________________
merge_8 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_8[0][0]          
____________________________________________________________________________________________________
merge_9 (Merge)                    (None, 100, 20)     0           shared_emb[1][0]                 
                                                                   timedistributed_9[0][0]          
____________________________________________________________________________________________________
gru_10 (GRU)                       (None, 50)          10650       merge_8[0][0]                    
____________________________________________________________________________________________________
gru_11 (GRU)                       (None, 50)          10650       merge_9[0][0]                    
____________________________________________________________________________________________________
gru_12 (GRU)                       (None, 50)          10650       merge_10[0][0]                   
____________________________________________________________________________________________________
gru_13 (GRU)                       (None, 50)          10650       merge_11[0][0]                   
____________________________________________________________________________________________________
gru_14 (GRU)                       (None, 50)          10650       merge_12[0][0]                   
____________________________________________________________________________________________________
gru_16 (GRU)                       (None, 50)          10650       merge_13[0][0]                   
____________________________________________________________________________________________________
gru_17 (GRU)                       (None, 50)          10650       merge_14[0][0]                   
____________________________________________________________________________________________________
gru_18 (GRU)                       (None, 50)          10650       merge_15[0][0]                   
____________________________________________________________________________________________________
gru_19 (GRU)                       (None, 50)          10650       merge_16[0][0]                   
____________________________________________________________________________________________________
gru_2 (GRU)                        (None, 50)          10650       merge_1[0][0]                    
____________________________________________________________________________________________________
gru_20 (GRU)                       (None, 50)          10650       merge_17[0][0]                   
____________________________________________________________________________________________________
gru_21 (GRU)                       (None, 50)          10650       merge_18[0][0]                   
____________________________________________________________________________________________________
gru_23 (GRU)                       (None, 50)          10650       merge_19[0][0]                   
____________________________________________________________________________________________________
gru_24 (GRU)                       (None, 50)          10650       merge_20[0][0]                   
____________________________________________________________________________________________________
gru_25 (GRU)                       (None, 50)          10650       merge_21[0][0]                   
____________________________________________________________________________________________________
gru_26 (GRU)                       (None, 50)          10650       merge_22[0][0]                   
____________________________________________________________________________________________________
gru_27 (GRU)                       (None, 50)          10650       merge_23[0][0]                   
____________________________________________________________________________________________________
gru_28 (GRU)                       (None, 50)          10650       merge_24[0][0]                   
____________________________________________________________________________________________________
gru_3 (GRU)                        (None, 50)          10650       merge_2[0][0]                    
____________________________________________________________________________________________________
gru_4 (GRU)                        (None, 50)          10650       merge_3[0][0]                    
____________________________________________________________________________________________________
gru_5 (GRU)                        (None, 50)          10650       merge_4[0][0]                    
____________________________________________________________________________________________________
gru_6 (GRU)                        (None, 50)          10650       merge_5[0][0]                    
____________________________________________________________________________________________________
gru_7 (GRU)                        (None, 50)          10650       merge_6[0][0]                    
____________________________________________________________________________________________________
gru_9 (GRU)                        (None, 50)          10650       merge_7[0][0]                    
____________________________________________________________________________________________________
merge_25 (Merge)                   (None, 1200)        0           gru_2[0][0]                      
                                                                   gru_3[0][0]                      
                                                                   gru_4[0][0]                      
                                                                   gru_5[0][0]                      
                                                                   gru_6[0][0]                      
                                                                   gru_7[0][0]                      
                                                                   gru_9[0][0]                      
                                                                   gru_10[0][0]                     
                                                                   gru_11[0][0]                     
                                                                   gru_12[0][0]                     
                                                                   gru_13[0][0]                     
                                                                   gru_14[0][0]                     
                                                                   gru_16[0][0]                     
                                                                   gru_17[0][0]                     
                                                                   gru_18[0][0]                     
                                                                   gru_19[0][0]                     
                                                                   gru_20[0][0]                     
                                                                   gru_21[0][0]                     
                                                                   gru_23[0][0]                     
                                                                   gru_24[0][0]                     
                                                                   gru_25[0][0]                     
                                                                   gru_26[0][0]                     
                                                                   gru_27[0][0]                     
                                                                   gru_28[0][0]                     
____________________________________________________________________________________________________
dense_1 (Dense)                    (None, 40)          48040       merge_25[0][0]                   
____________________________________________________________________________________________________
srelu_1 (SReLU)                    (None, 40)          160         dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 40)          0           srelu_1[0][0]                    
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 22)          902         dropout_1[0][0]                  
____________________________________________________________________________________________________
rsenses (Activation)               (None, 22)          0           dense_2[0][0]                    
====================================================================================================
Total params: 1185006
____________________________________________________________________________________________________
Epoch 1/200
281s - loss: 0.3191 - acc: 0.9572 - val_loss: 2.8720 - val_acc: 0.0000e+00
Epoch 2/200
279s - loss: 0.1617 - acc: 0.9610 - val_loss: 3.0155 - val_acc: 0.0963
Epoch 3/200
279s - loss: 0.1464 - acc: 0.9617 - val_loss: 2.9034 - val_acc: 0.1167
Epoch 4/200
280s - loss: 0.1381 - acc: 0.9627 - val_loss: 2.7794 - val_acc: 0.1275
Epoch 5/200
280s - loss: 0.1301 - acc: 0.9643 - val_loss: 2.5040 - val_acc: 0.1954
Epoch 6/200
278s - loss: 0.1245 - acc: 0.9642 - val_loss: 2.2583 - val_acc: 0.2171
Epoch 7/200
277s - loss: 0.1227 - acc: 0.9638 - val_loss: 2.3793 - val_acc: 0.1940
Epoch 8/200
280s - loss: 0.1193 - acc: 0.9642 - val_loss: 2.2455 - val_acc: 0.2212
Epoch 9/200
280s - loss: 0.1235 - acc: 0.9646 - val_loss: 2.2363 - val_acc: 0.2659
Epoch 10/200
280s - loss: 0.1180 - acc: 0.9649 - val_loss: 2.2268 - val_acc: 0.2714
Epoch 11/200
280s - loss: 0.1102 - acc: 0.9649 - val_loss: 2.2053 - val_acc: 0.2700
Epoch 12/200
290s - loss: 0.1130 - acc: 0.9653 - val_loss: 2.5057 - val_acc: 0.2144
Epoch 13/200
292s - loss: 0.1091 - acc: 0.9655 - val_loss: 2.2274 - val_acc: 0.1886
Epoch 14/200
291s - loss: 0.1100 - acc: 0.9657 - val_loss: 2.2436 - val_acc: 0.1832
Epoch 15/200
293s - loss: 0.1065 - acc: 0.9655 - val_loss: 2.1431 - val_acc: 0.2944
Epoch 16/200
292s - loss: 0.1065 - acc: 0.9659 - val_loss: 2.1292 - val_acc: 0.2768
Epoch 17/200
292s - loss: 0.1043 - acc: 0.9664 - val_loss: 2.1875 - val_acc: 0.2836
Epoch 18/200
292s - loss: 0.1073 - acc: 0.9647 - val_loss: 2.1403 - val_acc: 0.2564
Epoch 19/200
293s - loss: 0.1040 - acc: 0.9661 - val_loss: 2.1425 - val_acc: 0.2632
Epoch 20/200
292s - loss: 0.1044 - acc: 0.9667 - val_loss: 2.1609 - val_acc: 0.2795
Epoch 21/200
291s - loss: 0.1015 - acc: 0.9677 - val_loss: 2.1622 - val_acc: 0.2727
Epoch 22/200
292s - loss: 0.1000 - acc: 0.9675 - val_loss: 2.1473 - val_acc: 0.2510
Epoch 23/200
292s - loss: 0.0973 - acc: 0.9679 - val_loss: 2.1752 - val_acc: 0.1777
Epoch 24/200
288s - loss: 0.1015 - acc: 0.9666 - val_loss: 2.1498 - val_acc: 0.2782
Epoch 25/200
291s - loss: 0.1010 - acc: 0.9662 - val_loss: 2.1824 - val_acc: 0.2090
Epoch 26/200
292s - loss: 0.1021 - acc: 0.9669 - val_loss: 2.2034 - val_acc: 0.2578
Epoch 27/200
292s - loss: 0.1041 - acc: 0.9666 - val_loss: 2.2602 - val_acc: 0.2592


{"acc": 0.96658958589410504, "loss": -0.29443690637720488, "val_acc_max": 0.29443690637720488, "val_loss_min": 2.1291923610293884, "status": "ok", "val_acc": 0.25915875169606511, "loss_": 0.10409507931699988, "epochs_len": 27, "acc_max": 0.96791906904623004, "loss_min": 0.097253038445649115, "val_loss": 2.2602450799100922}

Currently Loaded Modulefiles:
  1) intel/2017.0

Job script resource usage:
       JobID  MaxVMSize     MaxRSS 
------------ ---------- ---------- 
16167505.ba+  17064232K  15641075K 

Job step resource usage:
       JobID    JobName  AllocCPUS  MaxVMSize     MaxRSS    Elapsed ExitCode 
------------ ---------- ---------- ---------- ---------- ---------- -------- 
16167505     rnn-glove+          2                         02:49:02      0:0 

Job 16167505 ("rnn-glove-wikipedia-gigawords") completed on c17-20 at tor dec 15 00:04:20 CET 2016
